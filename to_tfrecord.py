import json
import os
import io
import sys

import tensorflow as tf
from PIL import Image

# for the object_detection.utils import below, you must also install models from tensorflow (separate from 
# installing tensorflow.
# see https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md
from object_detection.utils import dataset_util


#filenames and other constants
CURR_DIR = '/home/mark/Desktop/die_detection/'
TRAIN_TFR_PATH = os.path.join(CURR_DIR, 'train_image_records.tfrecords')
TEST_TFR_PATH = os.path.join(CURR_DIR, 'test_image_records.tfrecords')
IMAGES_PATH = "/home/mark/Desktop/die_detection/7.16.18/"


def convert_object_information(image_data):
    """
    A convenience function to get a dictionary of object information  
    for a single image and return them in an easier to use dictionary form
    This is a custom function to handle json of the following form:
        {
        "annotations": [
            {
                "class": "rect",
                "height": 49.942548232907825,
                "width": 152.68150459774665,
                "x": 1128.7015900637164,
                "y": 280.7484675664174
            },
            {
                "class": "rect",
                "height": 50.29928072028571,
                "width": 151.61130713561283,
                "x": 1282.096559636219,
                "y": 276.8244102052604
            },
            {
                "class": "rect",
                "height": 36.05075394625766,
                "width": 107.55141593966869,
                "x": 1073.411198749822,
                "y": 182.95757627725766
            }

        ],
        "class": "image",
        "filename": "folder_with_images/001.jpg"
    }, ...]
   
    where "annotations" stands for the bounding boxes in a single image
    This is the format generated by Sloth image labeling tool.
    
    Args: 
    image_data
    Returns: 
    object_info: A dictionary of image information and lists of object information
    """
    
    #get image filename, width, height
    
    file_path = image_data['filename']
    file_name = bytes(file_path, 'utf-8')
    
    with tf.gfile.GFile(IMAGES_PATH + file_path, 'rb') as fid:
        encoded_jpg = fid.read()
    
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    img = Image.open(encoded_jpg_io)
    width, height = img.size
   
    obj_list = image_data['annotations']    
  
    obj_info = {
                'height': height, 
                'width': width, 
                'filename': file_name,
                'encoded': encoded_jpg,
                'format': b'jpg',
                #there is only one class we are detecting here
                'classes_label': [1 for x in obj_list],
                'classes_text': [b'sign' for x in obj_list],
                'xmins': [],
                'ymins': [],
                'xmaxs': [],
                'ymaxs': []                           
               }
    
    for obj_data in obj_list:
        xmin = obj_data['x']
        ymin = obj_data['y']
        box_height = obj_data["height"]
        box_width = obj_data["width"]
        
        ymax = ymin + box_height
        xmax = xmin + box_width
     
        obj_info['xmins'].append(xmin/width)
        obj_info['ymins'].append(ymin/height)
        obj_info['xmaxs'].append(xmax/width)
        obj_info['ymaxs'].append(ymax/height)

    return obj_info  
    

# function to load object boxes for a single image
# modfied from from https://github.com/tensorflow/models/blob/
# master/research/object_detection/g3doc/using_your_own_dataset.md
def create_tf_example(image_data):
    """Creates a tf.Example proto from single image

    Args:
    image_data: The data associated with the image.

    Returns:
    example: The created tf.Example.
    """

    obj_info = convert_object_information(image_data)
    num_objs = len(obj_info['xmins'])

    tf_example = tf.train.Example(features=tf.train.Features(feature={
      'image/height': dataset_util.int64_feature(obj_info['height']),
      'image/width': dataset_util.int64_feature(obj_info['width']),
      'image/filename': dataset_util.bytes_feature(obj_info['filename']),
      'image/encoded': dataset_util.bytes_feature(obj_info['encoded']),
      'image/format': dataset_util.bytes_feature(obj_info['format']),
      'image/object/bbox/xmin': dataset_util.float_list_feature(obj_info['xmins']),
      'image/object/bbox/xmax': dataset_util.float_list_feature(obj_info['xmaxs']),
      'image/object/bbox/ymin': dataset_util.float_list_feature(obj_info['ymins']),
      'image/object/bbox/ymax': dataset_util.float_list_feature(obj_info['ymaxs']),
      'image/object/class/text': dataset_util.bytes_list_feature(obj_info['classes_text']),
      'image/object/class/label': dataset_util.int64_list_feature(obj_info['classes_label'])
    }))
    return tf_example



def main():
# write training and test TFRecords to file
    with open(CURR_DIR + 'dice_annotations.json') as f:
        images_data = json.load(f)

    #split images_data into training and test sets
    num_images = len(images_data)
    num_train = int(0.8 * num_images)
    num_test = num_images - num_train

    train_images_data = images_data[:num_train]
    test_images_data = images_data[num_train:]

    print("{} training images, {} test images".format(len(train_images_data), len(test_images_data)))

    writer = tf.python_io.TFRecordWriter(TRAIN_TFR_PATH)   

    for image_data in train_images_data:
        example = create_tf_example(image_data)
        writer.write(example.SerializeToString())
    writer.close()
    sys.stdout.flush()

    writer = tf.python_io.TFRecordWriter(TEST_TFR_PATH)   

    for image_data in test_images_data:
        example = create_tf_example(image_data)
        writer.write(example.SerializeToString())
    writer.close()
    sys.stdout.flush()


if __name__ == "__main__":
    main()